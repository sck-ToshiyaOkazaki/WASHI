import streamlit as st
import pandas as pd
import sqlite3
import os
from datetime import datetime, date
import traceback

st.set_page_config(
    page_title="ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ - DBç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'file_upload_error' not in st.session_state:
    st.session_state.file_upload_error = None

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
DB_PATH = "./load/SONY.db"

def safe_read_csv(uploaded_file):
    """å®‰å…¨ã«CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€åº¦ãƒã‚¤ãƒˆå½¢å¼ã§èª­ã¿è¾¼ã‚€
        if uploaded_file is not None:
            file_content = uploaded_file.read()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’å…ˆé ­ã«æˆ»ã™
            uploaded_file.seek(0)
            
            # pandasã§CSVã‚’èª­ã¿è¾¼ã¿
            df = pd.read_csv(uploaded_file)
            
            return df, None
    except UnicodeDecodeError:
        try:
            # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼ã®å ´åˆã€ç•°ãªã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦ã™
            uploaded_file.seek(0)
            df = pd.read_csv(uploaded_file, encoding='shift_jis')
            return df, None
        except Exception as e:
            return None, f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {str(e)}"
    except Exception as e:
        return None, f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}"

def init_database():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–"""
    # çµ¶å¯¾ãƒ‘ã‚¹ã§ç¢ºå®Ÿã«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆ
    db_dir = os.path.abspath(os.path.dirname(DB_PATH))
    db_file = os.path.abspath(DB_PATH)
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    os.makedirs(db_dir, exist_ok=True)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    conn = sqlite3.connect(db_file)
    conn.close()
    
    # ä½œæˆç¢ºèªã®ãŸã‚ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±
    if os.path.exists(db_file):
        st.info(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒä½œæˆã•ã‚Œã¾ã—ãŸ: {db_file}")
    else:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä½œæˆã«å¤±æ•—: {db_file}")
    
    return db_file

def create_indexes_for_log_table():
    """LOGãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ"""
    try:
        db_file = os.path.abspath(DB_PATH)
        conn = sqlite3.connect(db_file)
        cursor = conn.cursor()
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã®ã¿ï¼‰
        indexes = [
            "CREATE INDEX IF NOT EXISTS idx_log_sub_lot_type ON LOG(SUB_LOT_TYPE)",
            "CREATE INDEX IF NOT EXISTS idx_log_lot_id ON LOG(LOT_ID)", 
            "CREATE INDEX IF NOT EXISTS idx_log_eqp_id ON LOG(EQP_ID)",
            "CREATE INDEX IF NOT EXISTS idx_log_stime ON LOG(STIME)",
            "CREATE INDEX IF NOT EXISTS idx_log_prod_grp_id ON LOG(PROD_GRP_ID)",
            "CREATE INDEX IF NOT EXISTS idx_log_prod_type ON LOG(PROD_TYPE)",
            "CREATE INDEX IF NOT EXISTS idx_log_ope_no ON LOG(OPE_NO)",
            "CREATE INDEX IF NOT EXISTS idx_log_run_time ON LOG(RUN_TIME)",
            "CREATE INDEX IF NOT EXISTS idx_log_wait_time ON LOG(WAIT_TIME)"
        ]
        
        for index_sql in indexes:
            cursor.execute(index_sql)
        
        conn.commit()
        conn.close()
        return True
    except Exception as e:
        st.error(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False

def save_data_to_db(df, table_name, replace=True):
    """ãƒ‡ãƒ¼ã‚¿ã‚’SQLiteã«ä¿å­˜"""
    try:
        db_file = os.path.abspath(DB_PATH)
        print(f"[DEBUG] ãƒ‡ãƒ¼ã‚¿ä¿å­˜é–‹å§‹: ãƒ†ãƒ¼ãƒ–ãƒ«={table_name}, DB={db_file}")
        print(f"[DEBUG] ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(df)}è¡Œ, {len(df.columns)}åˆ—")
        
        conn = sqlite3.connect(db_file)
        
        if replace:
            # æ—¢å­˜ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å‰Šé™¤ã—ã¦æ–°è¦ä½œæˆ
            df.to_sql(table_name, conn, if_exists='replace', index=False)
            print(f"[DEBUG] ãƒ†ãƒ¼ãƒ–ãƒ« {table_name} ã‚’ç½®æ›ä¿å­˜ã—ã¾ã—ãŸ")
        else:
            # ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            df.to_sql(table_name, conn, if_exists='append', index=False)
            print(f"[DEBUG] ãƒ†ãƒ¼ãƒ–ãƒ« {table_name} ã«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
        
        conn.close()
        
        # ä¿å­˜ç¢ºèª
        conn = sqlite3.connect(db_file)
        cursor = conn.cursor()
        cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
        count = cursor.fetchone()[0]
        conn.close()
        
        print(f"[DEBUG] ä¿å­˜ç¢ºèª: ãƒ†ãƒ¼ãƒ–ãƒ« {table_name} ã« {count} è¡Œã®ãƒ‡ãƒ¼ã‚¿")
        st.success(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜æˆåŠŸ: {table_name} ({count}è¡Œ)")
        
        return True
    except Exception as e:
        error_msg = f"ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}"
        print(f"[DEBUG] {error_msg}")
        st.error(error_msg)
        return False

def get_existing_tables():
    """æ—¢å­˜ã®ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    try:
        db_file = os.path.abspath(DB_PATH)
        conn = sqlite3.connect(db_file)
        cursor = conn.cursor()
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        tables = [row[0] for row in cursor.fetchall()]
        conn.close()
        return tables
    except Exception as e:
        st.error(f"ãƒ†ãƒ¼ãƒ–ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return []

def delete_tables(table_names):
    """æŒ‡å®šã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å‰Šé™¤"""
    try:
        db_file = os.path.abspath(DB_PATH)
        conn = sqlite3.connect(db_file)
        cursor = conn.cursor()
        
        for table_name in table_names:
            cursor.execute(f"DROP TABLE IF EXISTS {table_name}")
        
        conn.commit()
        conn.close()
        return True
    except Exception as e:
        st.error(f"ãƒ†ãƒ¼ãƒ–ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False

def get_table_info(table_name):
    """ãƒ†ãƒ¼ãƒ–ãƒ«ã®æƒ…å ±ã‚’å–å¾—"""
    try:
        db_file = os.path.abspath(DB_PATH)
        conn = sqlite3.connect(db_file)
        df = pd.read_sql_query(f"SELECT COUNT(*) as row_count FROM {table_name}", conn)
        row_count = df.iloc[0]['row_count']
        
        # ã‚«ãƒ©ãƒ æƒ…å ±ã‚’å–å¾—
        cursor = conn.cursor()
        cursor.execute(f"PRAGMA table_info({table_name})")
        columns = cursor.fetchall()
        col_count = len(columns)
        
        conn.close()
        return row_count, col_count
    except Exception as e:
        return 0, 0

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹
st.title("ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ - DBç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ")

# ã‚¨ãƒ©ãƒ¼çŠ¶æ…‹ã®è¡¨ç¤º
if st.session_state.get('file_upload_error'):
    st.error(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {st.session_state.file_upload_error}")
    st.info("ğŸ’¡ è§£æ±ºæ–¹æ³•: ãƒ–ãƒ©ã‚¦ã‚¶ã‚’æ›´æ–°ã™ã‚‹ã‹ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’å°ã•ãã—ã¦ãŠè©¦ã—ãã ã•ã„")
    if st.button("ã‚¨ãƒ©ãƒ¼ã‚’ã‚¯ãƒªã‚¢"):
        st.session_state.file_upload_error = None
        st.rerun()

st.markdown("---")

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
init_database()

# æ©Ÿèƒ½1: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨DBæ ¼ç´
st.header("ğŸ”„ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨DBæ ¼ç´")

# ã‚¿ãƒ–ã§7ç¨®é¡ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†é›¢
tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
    "å“è³ªåŸºæº–è¡¨", "åŒæ™‚ç€å·¥æ•°", "åˆ¶ç´„æ™‚é–“", "å‡¦ç†å®Ÿç¸¾", "æŠ•å…¥è¨ˆç”»", "åˆåŒãƒ•ãƒ­ãƒ¼", "ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ"
])

with tab1:
    st.subheader("å“è³ªåŸºæº–è¡¨ã®èª­ã¿è¾¼ã¿")
    
    col1, col2 = st.columns(2)
    
    with col1:
        uploaded_file = st.file_uploader(
            "å“è³ªåŸºæº–è¡¨ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
            type=['csv'],
            key="flowinfo"
        )
    
    with col2:
        selected_date = st.date_input(
            "å¹´æœˆæ—¥ã‚’é¸æŠã—ã¦ãã ã•ã„",
            value=date.today(),
            key="flowinfo_date"
        )
    
    if uploaded_file is not None:
        col1, col2 = st.columns(2)
        with col1:
            load_data = st.button("ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿", key="load_flowinfo")
        
        if load_data or "flowinfo_df" in st.session_state:
            try:
                if load_data:
                    df, error = safe_read_csv(uploaded_file)
                    if error:
                        st.error(f"âŒ {error}")
                    else:
                        st.session_state.flowinfo_df = df
                        st.success(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆ{len(df)}è¡Œ, {len(df.columns)}åˆ—ï¼‰")
                
                if "flowinfo_df" in st.session_state:
                    df = st.session_state.flowinfo_df
                    st.dataframe(df.head(), use_container_width=True)
                    
                    with col2:
                        if st.button("ğŸ’¾ å“è³ªåŸºæº–è¡¨ã‚’DBã«ä¿å­˜", key="save_flowinfo"):
                            date_str = selected_date.strftime("%Y%m%d")
                            table_name = f"FlowInfo_{date_str}"
                            
                            if save_data_to_db(df, table_name, replace=True):
                                st.success(f"âœ… ãƒ†ãƒ¼ãƒ–ãƒ« '{table_name}' ã«ä¿å­˜ã—ã¾ã—ãŸ")
                                st.rerun()
                        
            except Exception as e:
                st.error(f"âŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                st.error("ãƒ–ãƒ©ã‚¦ã‚¶ã‚’æ›´æ–°ã—ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„")

with tab2:
    st.subheader("åŒæ™‚ç€å·¥æ•°ã®èª­ã¿è¾¼ã¿")
    
    uploaded_file = st.file_uploader(
        "åŒæ™‚ç€å·¥æ•°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=['csv'],
        key="eqp_batch"
    )
    
    if uploaded_file is not None:
        col1, col2 = st.columns(2)
        with col1:
            load_data = st.button("ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿", key="load_eqp_batch")
        
        if load_data or "eqp_batch_df" in st.session_state:
            try:
                if load_data:
                    df, error = safe_read_csv(uploaded_file)
                    if error:
                        st.error(f"âŒ {error}")
                    else:
                        st.session_state.eqp_batch_df = df
                        st.success(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆ{len(df)}è¡Œ, {len(df.columns)}åˆ—ï¼‰")
                
                if "eqp_batch_df" in st.session_state:
                    df = st.session_state.eqp_batch_df
                    st.dataframe(df.head(), use_container_width=True)
                    
                    with col2:
                        if st.button("ğŸ’¾ åŒæ™‚ç€å·¥æ•°ã‚’DBã«ä¿å­˜", key="save_eqp_batch"):
                            if save_data_to_db(df, "eqp_batch", replace=True):
                                st.success("âœ… ãƒ†ãƒ¼ãƒ–ãƒ« 'eqp_batch' ã«ä¿å­˜ã—ã¾ã—ãŸ")
                                st.rerun()
                        
            except Exception as e:
                st.error(f"âŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                st.error("ãƒ–ãƒ©ã‚¦ã‚¶ã‚’æ›´æ–°ã—ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„")

with tab3:
    st.subheader("åˆ¶ç´„æ™‚é–“ã®èª­ã¿è¾¼ã¿")
    
    uploaded_file = st.file_uploader(
        "åˆ¶ç´„æ™‚é–“ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=['csv'],
        key="qtime"
    )
    
    if uploaded_file is not None:
        col1, col2 = st.columns(2)
        with col1:
            load_data = st.button("ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿", key="load_qtime")
        
        if load_data or "qtime_df" in st.session_state:
            try:
                if load_data:
                    df, error = safe_read_csv(uploaded_file)
                    if error:
                        st.error(f"âŒ {error}")
                    else:
                        st.session_state.qtime_df = df
                        st.success(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆ{len(df)}è¡Œ, {len(df.columns)}åˆ—ï¼‰")
                
                if "qtime_df" in st.session_state:
                    df = st.session_state.qtime_df
                    st.dataframe(df.head(), use_container_width=True)
                    
                    with col2:
                        if st.button("ğŸ’¾ åˆ¶ç´„æ™‚é–“ã‚’DBã«ä¿å­˜", key="save_qtime"):
                            if save_data_to_db(df, "Qtime", replace=True):
                                st.success("âœ… ãƒ†ãƒ¼ãƒ–ãƒ« 'Qtime' ã«ä¿å­˜ã—ã¾ã—ãŸ")
                                st.rerun()
                        
            except Exception as e:
                st.error(f"âŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                st.error("ãƒ–ãƒ©ã‚¦ã‚¶ã‚’æ›´æ–°ã—ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„")

with tab4:
    st.subheader("å‡¦ç†å®Ÿç¸¾ã®èª­ã¿è¾¼ã¿")
    
    uploaded_file = st.file_uploader(
        "å‡¦ç†å®Ÿç¸¾ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=['csv'],
        key="log"
    )
    
    if uploaded_file is not None:
        col1, col2 = st.columns(2)
        with col1:
            load_data = st.button("ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿", key="load_log")
        
        if load_data or "log_df" in st.session_state:
            try:
                if load_data:
                    df, error = safe_read_csv(uploaded_file)
                    if error:
                        st.error(f"âŒ {error}")
                    else:
                        st.session_state.log_df = df
                        
                        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å¯¾è±¡ã‚«ãƒ©ãƒ ã®ç¢ºèª
                        required_columns = [
                            'SUB_LOT_TYPE', 'LOT_ID', 'EQP_ID', 'STIME', 
                            'PROD_GRP_ID', 'PROD_TYPE', 'OPE_NO', 'RUN_TIME', 'WAIT_TIME'
                        ]
                        existing_columns = [col for col in required_columns if col in df.columns]
                        st.session_state.log_index_columns = existing_columns
                        
                        st.success(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆ{len(df)}è¡Œ, {len(df.columns)}åˆ—ï¼‰")
                
                if "log_df" in st.session_state:
                    df = st.session_state.log_df
                    st.dataframe(df.head(), use_container_width=True)
                    
                    if hasattr(st.session_state, 'log_index_columns') and st.session_state.log_index_columns:
                        st.info(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å¯¾è±¡ã‚«ãƒ©ãƒ : {', '.join(st.session_state.log_index_columns)}")
                    
                    with col2:
                        if st.button("ğŸ’¾ å‡¦ç†å®Ÿç¸¾ã‚’DBã«ä¿å­˜", key="save_log"):
                            if save_data_to_db(df, "LOG", replace=True):
                                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
                                if create_indexes_for_log_table():
                                    st.success("âœ… ãƒ†ãƒ¼ãƒ–ãƒ« 'LOG' ã«ä¿å­˜ã—ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¾ã—ãŸ")
                                else:
                                    st.success("âœ… ãƒ†ãƒ¼ãƒ–ãƒ« 'LOG' ã«ä¿å­˜ã—ã¾ã—ãŸï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã¯å¤±æ•—ï¼‰")
                                st.rerun()
                        
            except Exception as e:
                st.error(f"âŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                st.error("ãƒ–ãƒ©ã‚¦ã‚¶ã‚’æ›´æ–°ã—ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„")

with tab5:
    st.subheader("æŠ•å…¥è¨ˆç”»ã®èª­ã¿è¾¼ã¿")
    
    uploaded_file = st.file_uploader(
        "æŠ•å…¥è¨ˆç”»ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=['csv'],
        key="plan"
    )
    
    if uploaded_file is not None:
        col1, col2 = st.columns(2)
        with col1:
            load_data = st.button("ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿", key="load_plan")
        
        if load_data or "plan_df" in st.session_state:
            try:
                if load_data:
                    df, error = safe_read_csv(uploaded_file)
                    if error:
                        st.error(f"âŒ {error}")
                    else:
                        st.session_state.plan_df = df
                        st.success(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆ{len(df)}è¡Œ, {len(df.columns)}åˆ—ï¼‰")
                
                if "plan_df" in st.session_state:
                    df = st.session_state.plan_df
                    st.dataframe(df.head(), use_container_width=True)
                    
                    with col2:
                        if st.button("ğŸ’¾ æŠ•å…¥è¨ˆç”»ã‚’DBã«ä¿å­˜", key="save_plan"):
                            if save_data_to_db(df, "plan", replace=True):
                                st.success("âœ… ãƒ†ãƒ¼ãƒ–ãƒ« 'plan' ã«ä¿å­˜ã—ã¾ã—ãŸ")
                                st.rerun()
                        
            except Exception as e:
                st.error(f"âŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                st.error("ãƒ–ãƒ©ã‚¦ã‚¶ã‚’æ›´æ–°ã—ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„")

with tab6:
    st.subheader("åˆåŒãƒ•ãƒ­ãƒ¼ã®èª­ã¿è¾¼ã¿")
    
    uploaded_file = st.file_uploader(
        "åˆåŒãƒ•ãƒ­ãƒ¼ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=['csv'],
        key="uflow"
    )
    
    if uploaded_file is not None:
        col1, col2 = st.columns(2)
        with col1:
            load_data = st.button("ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿", key="load_uflow")
        
        if load_data or "uflow_df" in st.session_state:
            try:
                if load_data:
                    df, error = safe_read_csv(uploaded_file)
                    if error:
                        st.error(f"âŒ {error}")
                    else:
                        st.session_state.uflow_df = df
                        st.success(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆ{len(df)}è¡Œ, {len(df.columns)}åˆ—ï¼‰")
                
                if "uflow_df" in st.session_state:
                    df = st.session_state.uflow_df
                    st.dataframe(df.head(), use_container_width=True)
                    
                    with col2:
                        if st.button("ğŸ’¾ åˆåŒãƒ•ãƒ­ãƒ¼ã‚’DBã«ä¿å­˜", key="save_uflow"):
                            if save_data_to_db(df, "uflow", replace=True):
                                st.success("âœ… ãƒ†ãƒ¼ãƒ–ãƒ« 'uflow' ã«ä¿å­˜ã—ã¾ã—ãŸ")
                                st.rerun()
                        
            except Exception as e:
                st.error(f"âŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                st.error("ãƒ–ãƒ©ã‚¦ã‚¶ã‚’æ›´æ–°ã—ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„")

with tab7:
    st.subheader("ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®èª­ã¿è¾¼ã¿")
    
    uploaded_file = st.file_uploader(
        "ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=['csv'],
        key="layout"
    )
    
    if uploaded_file is not None:
        col1, col2 = st.columns(2)
        with col1:
            load_data = st.button("ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿", key="load_layout")
        
        if load_data or "layout_df" in st.session_state:
            try:
                if load_data:
                    df, error = safe_read_csv(uploaded_file)
                    if error:
                        st.error(f"âŒ {error}")
                    else:
                        st.session_state.layout_df = df
                        st.success(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆ{len(df)}è¡Œ, {len(df.columns)}åˆ—ï¼‰")
                
                if "layout_df" in st.session_state:
                    df = st.session_state.layout_df
                    st.dataframe(df.head(), use_container_width=True)
                    
                    with col2:
                        if st.button("ğŸ’¾ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’DBã«ä¿å­˜", key="save_layout"):
                            if save_data_to_db(df, "layout", replace=True):
                                st.success("âœ… ãƒ†ãƒ¼ãƒ–ãƒ« 'layout' ã«ä¿å­˜ã—ã¾ã—ãŸ")
                                st.rerun()
                        
            except Exception as e:
                st.error(f"âŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                st.error("ãƒ–ãƒ©ã‚¦ã‚¶ã‚’æ›´æ–°ã—ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„")

# æ©Ÿèƒ½2: ãƒ†ãƒ¼ãƒ–ãƒ«å‰Šé™¤æ©Ÿèƒ½
st.markdown("---")
st.header("ğŸ—‘ï¸DBãƒ†ãƒ¼ãƒ–ãƒ«ç®¡ç†")

# ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã®æ›´æ–°ãƒœã‚¿ãƒ³
col1, col2 = st.columns([1, 4])
with col1:
    refresh_tables = st.button("ğŸ”„ ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’æ›´æ–°", key="refresh_tables")

# æ—¢å­˜ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—
if refresh_tables or "existing_tables" not in st.session_state:
    st.session_state.existing_tables = get_existing_tables()

existing_tables = st.session_state.existing_tables

if existing_tables:
    st.subheader("æ—¢å­˜ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§")
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã‚’è¡¨ç¤º
    table_info = []
    for table in existing_tables:
        row_count, col_count = get_table_info(table)
        table_info.append({
            "ãƒ†ãƒ¼ãƒ–ãƒ«å": table,
            "ãƒ‡ãƒ¼ã‚¿è¡Œæ•°": row_count,
            "ã‚«ãƒ©ãƒ æ•°": col_count
        })
    
    df_tables = pd.DataFrame(table_info)
    st.dataframe(df_tables, use_container_width=True)
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«å‰Šé™¤æ©Ÿèƒ½
    st.subheader("ãƒ†ãƒ¼ãƒ–ãƒ«å‰Šé™¤")
    selected_tables = st.multiselect(
        "å‰Šé™¤ã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        existing_tables
    )
    
    if selected_tables:
        if st.button("ğŸ—‘ï¸ é¸æŠã—ãŸãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å‰Šé™¤", type="secondary"):
            if delete_tables(selected_tables):
                st.success(f"âœ… {len(selected_tables)}å€‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                # ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’æ›´æ–°
                st.session_state.existing_tables = get_existing_tables()
                st.rerun()
            else:
                st.error("âŒ ãƒ†ãƒ¼ãƒ–ãƒ«å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ")
else:
    st.info("ğŸ“‹ ç¾åœ¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãƒ†ãƒ¼ãƒ–ãƒ«ã¯å­˜åœ¨ã—ã¾ã›ã‚“")

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±
st.markdown("---")
st.subheader("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±")
col1, col2 = st.columns(2)

db_file = os.path.abspath(DB_PATH)

with col1:
    st.metric("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹", db_file)

with col2:
    if os.path.exists(db_file):
        file_size = os.path.getsize(db_file)
        st.metric("ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º", f"{file_size:,} bytes")
    else:
        st.metric("ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º", "0 bytes (æœªä½œæˆ)")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("**SONY DBç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ** | ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ãƒ»ä¿å­˜ãƒ»ç®¡ç†")
